{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple source modeling\n",
    "Trying to iron out all the confusion on how to calculate source parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sym\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from obspy import Trace, Stream, UTCDateTime\n",
    "import obsplus\n",
    "from obsplus.utils.time import to_utc\n",
    "\n",
    "from mopy import StatsGroup, TraceGroup, SpectrumGroup\n",
    "\n",
    "t, a, b, c, f = sym.symbols('t a b c f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Model\n",
    "\n",
    "We will use a simple guassian as a source model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gausian and derivative/integral\n",
    "gaus = a * sym.exp((-(t - b)**2) / (2 * c **2))\n",
    "d_gaus = sym.diff(gaus, t)\n",
    "int_gaus = sym.integrate(gaus, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get freq domain\n",
    "F_gaus = sym.fourier_transform(gaus, t, f).rewrite(sym.Integral)\n",
    "F_d_gaus = sym.fourier_transform(d_gaus, t, f).rewrite(sym.Integral)\n",
    "F_int_gaus = sym.fourier_transform(int_gaus, t, f).rewrite(sym.Integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gaus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get numpy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gaus = sym.lambdify([t, a, b, c], gaus)\n",
    "get_d_gaus = sym.lambdify([t, a, b, c], d_gaus)\n",
    "get_int_gaus = sym.lambdify([t, a, b, c], int_gaus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next generate source time series and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2, dt = 0, 10.24, 0.01\n",
    "a, b, c = 0.1, 5, np.sqrt(3)\n",
    "x_orig = np.arange(t1, t2+1, dt)\n",
    "x = x_orig\n",
    "# get source in 1) displacement 2) velocity\n",
    "# dt = 0.01\n",
    "# a, b, c = 0.1, 5, np.sqrt(2)\n",
    "# # x = np.arange(0, 10/2, dt)\n",
    "# x = np.arange(0, 10, dt)\n",
    "ns = {}\n",
    "\n",
    "# Without zero-padding\n",
    "# source_disp_st = \n",
    "source_disp = np.zeros(len(x))\n",
    "source_disp[0:len(x)] = get_gaus(x, a=a, b=b, c=c)  # displacement\n",
    "ns[\"source\"] = len(x)\n",
    "source_vel = np.zeros(len(x))\n",
    "source_vel[0:len(x)] = get_d_gaus(x, a=a, b=b, c=c)  # velocity\n",
    "# With zero padding and a serious discontinuity\n",
    "# x = np.arange(t1, (t2+1)/2, dt)\n",
    "# dis_source_disp = np.zeros(len(x)*2)\n",
    "# dis_source_disp[0:len(x)] = get_gaus(x, a=a, b=b, c=c)  # displacement\n",
    "# dis_source_vel = np.zeros(len(x)*2)\n",
    "# dis_source_vel[0:len(x)] = get_d_gaus(x, a=a, b=b, c=c)  # velocity\n",
    "x = np.arange(t1, (t2+1)*0.75, dt)\n",
    "ns[\"discosninuity\"] = len(x)\n",
    "dis_source_disp = np.zeros(len(x_orig))\n",
    "dis_source_disp[0:len(x)] = get_gaus(x, a=a, b=b, c=c)  # displacement\n",
    "dis_source_vel = np.zeros(len(x_orig))\n",
    "dis_source_vel[0:len(x)] = get_d_gaus(x, a=a, b=b, c=c)  # velocity\n",
    "# With zero padding, but relatively continuous\n",
    "# x = np.arange(t1, (t2+1)/2, dt)\n",
    "# zp_source_disp = np.zeros(len(x)*2)\n",
    "# zp_source_disp[0:len(x)] = get_gaus(x, a=a, b=b/2, c=c/2)  # displacement\n",
    "# zp_source_vel = np.zeros(len(x)*2)\n",
    "# zp_source_vel[0:len(x)] = get_d_gaus(x, a=a, b=b/2, c=c/2)  # velocity\n",
    "x = np.arange(t1, (t2+1)*0.75, dt)\n",
    "ns[\"zero_padded\"] = len(x)\n",
    "zp_source_disp = np.zeros(len(x_orig))\n",
    "zp_source_disp[0:len(x)] = get_gaus(x, a=a, b=b*0.75, c=c*0.75)  # displacement\n",
    "zp_source_vel = np.zeros(len(x_orig))\n",
    "zp_source_vel[0:len(x)] = get_d_gaus(x, a=a, b=b*0.75, c=c*0.75)  # velocity\n",
    "\n",
    "x = x_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "ax1.plot(x, source_disp)\n",
    "ax2.plot(x, dis_source_disp)\n",
    "ax3.plot(x, zp_source_disp)\n",
    "# plt.plot(x, source_disp)\n",
    "ax1.set_ylabel('displacement amplitude (m)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "ax1.plot(x, source_vel)\n",
    "ax2.plot(x, dis_source_vel)\n",
    "ax3.plot(x, zp_source_vel)\n",
    "ax1.set_ylabel('velocity amplitude (m/s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put all three source time series into MoPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = obsplus.load_dataset(\"coal_node\")\n",
    "# Load up some events\n",
    "cat = ds.event_client.get_events()\n",
    "# Load up a station inventory\n",
    "inv = ds.station_client.get_stations()\n",
    "# Generate a StatsGroup that can be used to create another StatsGroup\n",
    "sg = StatsGroup(catalog=cat, inventory=inv)\n",
    "\n",
    "# Two streams, one has the full data, the other has only part of it\n",
    "# (to see the effects of zero padding the data)\n",
    "df_contents = {\n",
    "    \"event_id\": [\"event1\", \"event1\", \"event1\"],\n",
    "    \"seed_id\": [\"UK.STA1..HHZ\", \"UK.STA2..HHZ\", \"UK.STA3..HHZ\"],\n",
    "    \"seed_id_less\": [\"UK.STA1..HH\", \"UK.STA2..HH\", \"UK.STA3..HH\"],\n",
    "    \"phase_hint\": [\"P\", \"P\", \"P\"],\n",
    "    \"time\": [np.datetime64(\"2020-01-01T00:00:01\"), np.datetime64(\"2020-01-01T00:00:01\"), np.datetime64(\"2020-01-01T00:00:01\")],\n",
    "    \"starttime\": [np.datetime64(\"2020-01-01T00:00:00\"), np.datetime64(\"2020-01-01T00:00:00\"), np.datetime64(\"2020-01-01T00:00:00\"),],\n",
    "    \"endtime\": [np.datetime64(\"2020-01-01T00:00:00\") + np.timedelta64(int(t2*1000), 'ms') - np.timedelta64(int(dt*1000), 'ms'), \n",
    "                np.datetime64(\"2020-01-01T00:00:00\") + np.timedelta64(int(t2//2*1000), 'ms') - np.timedelta64(int(dt*1000), 'ms'),\n",
    "                np.datetime64(\"2020-01-01T00:00:00\") + np.timedelta64(int(t2//2*1000), \"ms\") - np.timedelta64(int(dt*1000), \"ms\")\n",
    "               ],\n",
    "    \"ray_path_length_m\": [2000, 2000, 2000],\n",
    "    \"hyp_distance_m\": [2000, 2000, 2000],\n",
    "}\n",
    "df = pd.DataFrame(df_contents, columns=df_contents.keys())\n",
    "df.set_index(['phase_hint', 'event_id', 'seed_id_less', 'seed_id'], inplace=True)\n",
    "df[\"sampling_rate\"] = 1/dt\n",
    "sg = sg.new_from_dict(data=df)  # This is a weird way to do this\n",
    "\n",
    "st = Stream()\n",
    "tr = Trace(data=source_disp, header={\n",
    "    \"starttime\": to_utc(sg.data.iloc[0].starttime),\n",
    "    \"delta\": dt,\n",
    "    \"network\": \"UK\",\n",
    "    \"station\": \"STA1\",\n",
    "    \"channel\": \"HHZ\",\n",
    "})\n",
    "st.append(tr)\n",
    "tr = Trace(data=dis_source_disp, header={\n",
    "    \"starttime\": to_utc(sg.data.iloc[1].starttime),\n",
    "    \"delta\": dt,\n",
    "    \"network\": \"UK\",\n",
    "    \"station\": \"STA2\",\n",
    "    \"channel\": \"HHZ\",\n",
    "})\n",
    "st.append(tr)\n",
    "tr = Trace(data=zp_source_disp, header={\n",
    "    \"starttime\": to_utc(sg.data.iloc[2].starttime),\n",
    "    \"delta\": dt,\n",
    "    \"network\": \"UK\",\n",
    "    \"station\": \"STA3\",\n",
    "    \"channel\": \"HHZ\",\n",
    "})\n",
    "st.append(tr)\n",
    "tg = TraceGroup(sg, st.copy(), \"displacement\").fillna()  # START HERE... MAKE SURE TO CREATE THE STREAM BEFORE ADDING THE ZERO PADDING TO THE END TO ENSURE WE'RE GETTING THE RIGHT SAMPLE LENGTHS? BUT IT STILL SEEMS LIKE THERE WOULD BE A SAMPLE LENGTH DEPENDENCE THAT IS NOT ACCOUNTED FOR...\n",
    "\n",
    "spec = tg.dft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sg.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to the frequency domain and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft(ar, dt):\n",
    "    \"\"\"Return the fft of the array and its \"\"\"\n",
    "    fft_ar = np.fft.rfft(ar)\n",
    "    freq = np.fft.rfftfreq(len(ar), dt)\n",
    "    return freq, fft_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, source_disp_fft = get_fft(source_disp, dt)\n",
    "freqs, dis_source_disp_fft = get_fft(dis_source_disp, dt)\n",
    "freqs, zp_source_disp_fft = get_fft(zp_source_disp, dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "ax1.loglog(freqs, abs(source_disp_fft))\n",
    "ax2.loglog(freqs, abs(dis_source_disp_fft))\n",
    "ax3.loglog(freqs, abs(zp_source_disp_fft))\n",
    "ax1.set_ylabel('amplitude')\n",
    "\n",
    "ax1.loglog(spec.data.columns, abs(spec.data.iloc[0]), alpha=0.8)\n",
    "ax2.loglog(spec.data.columns, abs(spec.data.iloc[1]), alpha=0.8)\n",
    "ax3.loglog(spec.data.columns, abs(spec.data.iloc[2]), alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert back to the time domain and plot to make sure you get the input back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is necessary to divide by the sample spacing to get the correct amplitude..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_disp_rev = np.fft.irfft(source_disp_fft)\n",
    "dis_source_disp_rev = np.fft.irfft(dis_source_disp_fft)\n",
    "zp_source_disp_rev = np.fft.irfft(zp_source_disp_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "ax1.plot(x, source_disp_rev)\n",
    "ax2.plot(x, dis_source_disp_rev)\n",
    "ax3.plot(x, zp_source_disp_rev)\n",
    "# plt.plot(x, source_disp)\n",
    "ax1.set_ylabel('displacement amplitude (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the derivative in the time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel = np.gradient(source_disp, dt)\n",
    "dis_vel = np.gradient(dis_source_disp, dt)\n",
    "zp_vel = np.gradient(zp_source_disp, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat in the frequency domain and convert back to the time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_fft = 1j * 2 * np.pi * freqs * source_disp_fft\n",
    "vel_td = np.fft.irfft(vel_fft)\n",
    "\n",
    "dis_vel_fft = 1j * 2 * np.pi * freqs * dis_source_disp_fft\n",
    "dis_vel_td = np.fft.irfft(dis_vel_fft)\n",
    "\n",
    "zp_vel_fft = 1j * 2 * np.pi * freqs * zp_source_disp_fft\n",
    "zp_vel_td = np.fft.irfft(zp_vel_fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_v = spec.to_motion_type(\"velocity\")\n",
    "spec_to_td = np.fft.irfft(spec_v.data, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the analytical, numerical, and fft solutions and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "ax1.plot(x, source_vel)\n",
    "ax1.plot(x, vel)\n",
    "ax1.plot(x, vel_td, alpha=0.5)\n",
    "\n",
    "ax2.plot(x, dis_source_vel)\n",
    "ax2.plot(x, dis_vel)\n",
    "ax2.plot(x, dis_vel_td, alpha=0.5)\n",
    "\n",
    "ax3.plot(x, zp_source_vel)\n",
    "ax3.plot(x, zp_vel)\n",
    "ax3.plot(x, zp_vel_td, alpha=0.5)\n",
    "ax1.set_ylabel('velocity amplitude (m/s)')\n",
    "\n",
    "ax1.set_ylim(-0.05, 0.05)\n",
    "ax2.set_ylim(-0.25, 0.25)\n",
    "\n",
    "ax1.plot(x[:-100], spec_to_td[0], alpha=0.8)\n",
    "ax2.plot(x[:-100], spec_to_td[1], alpha=0.8)\n",
    "ax3.plot(x[:-100], spec_to_td[2], alpha=0.8)\n",
    "# ax2.loglog(spec_v.data.columns, abs(spec_v.data.iloc[1]), alpha=0.8)\n",
    "# ax3.loglog(spec_v.data.columns, abs(spec_v.data.iloc[2]), alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max Diffs:\", (source_vel - vel_td).max(), (dis_source_vel - dis_vel_td).max(), (zp_source_vel - zp_vel_td).max())\n",
    "print(\"Max Diffs:\", (source_vel[:-100] - spec_to_td[0]).max(), (dis_source_vel[:-100] - spec_to_td[1]).max(), (zp_source_vel[:-100] - spec_to_td).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the FFTs from each solution and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vel_fft = np.fft.rfft(source_vel)\n",
    "dis_source_vel_fft = np.fft.rfft(dis_source_vel)\n",
    "zp_source_vel_fft = np.fft.rfft(zp_source_vel)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "ax1.loglog(freqs, abs(source_vel_fft))\n",
    "ax1.loglog(freqs, abs(np.fft.rfft(vel)))\n",
    "ax1.loglog(freqs, abs(vel_fft), alpha=0.5)\n",
    "\n",
    "ax2.loglog(freqs, abs(dis_source_vel_fft))\n",
    "ax2.loglog(freqs, abs(np.fft.rfft(dis_vel)))\n",
    "ax2.loglog(freqs, abs(dis_vel_fft), alpha=0.5)\n",
    "           \n",
    "ax3.loglog(freqs, abs(zp_source_vel_fft))\n",
    "ax3.loglog(freqs, abs(np.fft.rfft(zp_vel)))\n",
    "ax3.loglog(freqs, abs(zp_vel_fft), alpha=0.5)\n",
    "\n",
    "ax1.loglog(spec_v.data.columns, abs(spec_v.data.iloc[0]))\n",
    "ax2.loglog(spec_v.data.columns, abs(spec_v.data.iloc[1]))\n",
    "ax3.loglog(spec_v.data.columns, abs(spec_v.data.iloc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(source_vel_fft).mean() - abs(spec_v.data.iloc[0]).mean(), \n",
    "      abs(dis_source_vel_fft).mean() - abs(spec_v.data.iloc[1]).mean(), \n",
    "      abs(zp_source_vel_fft).mean() - abs(spec_v.data.iloc[2]).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy\n",
    "Next we estimate energy and the equivalent in the freq domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time domain energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_energy = source_vel ** 2\n",
    "dis_source_energy = dis_source_vel ** 2\n",
    "zp_source_energy = zp_source_vel ** 2\n",
    "spec_energy = np.fft.irfft(spec_v.data, axis=1) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "ax1.plot(x, source_energy)\n",
    "ax1.plot(x[:-100], spec_energy[0], alpha=0.5)\n",
    "ax2.plot(x, dis_source_energy)\n",
    "ax2.plot(x[:-100], spec_energy[1], alpha=0.5)\n",
    "ax3.plot(x, zp_source_energy)\n",
    "ax3.plot(x[:-100], spec_energy[2], alpha=0.5)\n",
    "ax1.set_ylabel('amplitude (m^2/s^2)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_td = np.trapz(source_energy, dx=dt)\n",
    "energy_td = np.sum(source_energy)\n",
    "dis_energy_td = np.sum(dis_source_energy[0:len(x)//2])  # This should be half the energy of the first (and zero padding shouldn't make a big difference?)\n",
    "zp_energy_td = np.sum(zp_source_energy[0:len(x)//2])  # This should be twice the energy of the first because it's higher frequency (again, zero padding doesn't actuall matter)\n",
    "print(energy_td, dis_energy_td, zp_energy_td)\n",
    "print(np.sum(spec_energy, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency domain energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppsd(fft, n, dt):\n",
    "    \"\"\"Get the power spectral density? Or something close to it ;)\"\"\"\n",
    "#     print(abs(fft).min(), abs(fft).max())\n",
    "    fft_ar_sq = fft ** 2\n",
    "#     print(abs(fft_ar_sq).min(), abs(fft_ar_sq).max())\n",
    "    out = fft_ar_sq * (dt / n)\n",
    "#     print(abs(out).min(), abs(out).max())\n",
    "    # double non zero components to account for neg. frequencies\n",
    "    out[1:] *= 2\n",
    "#     print(abs(out).min(), abs(out).max())\n",
    "    freq = np.fft.rfftfreq(n, dt)\n",
    "    return freq, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs, ppsd_analytic = get_ppsd(np.fft.rfft(source_vel), len(source_vel), dt) # Analytical\n",
    "freqs, ppsd_time = get_ppsd(np.fft.rfft(vel), len(source_vel), dt) # Get velocity in time domain (should pretty closely match the analytical solution)\n",
    "freqs, ppsd_freq = get_ppsd(vel_fft, len(source_vel), dt) # Get velocity in frequency domain\n",
    "\n",
    "freqs, dis_ppsd_analytic = get_ppsd(np.fft.rfft(dis_source_vel), len(dis_source_vel), dt) # Analytical\n",
    "freqs, dis_ppsd_time = get_ppsd(np.fft.rfft(dis_vel), len(dis_source_vel), dt) # Get velocity in time domain\n",
    "freqs, dis_ppsd_freq = get_ppsd(dis_vel_fft, len(dis_source_vel), dt) # Get velocity in frequency domain\n",
    "\n",
    "freqs, zp_ppsd_analytic = get_ppsd(np.fft.rfft(zp_source_vel), len(zp_source_vel), dt) # Analytical\n",
    "freqs, zp_ppsd_time = get_ppsd(np.fft.rfft(zp_vel), len(zp_source_vel), dt) # Get velocity in time domain\n",
    "freqs, zp_ppsd_freq = get_ppsd(zp_vel_fft, len(zp_source_vel), dt) # Get velocity in frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_ppsd = spec_v.to_spectra_type(\"psd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_freqs, spec_ppsd1 = get_ppsd(spec_v.data.values, len(tg.data.columns), dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_ppsd1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "ax1.loglog(freqs, abs(ppsd_analytic))\n",
    "ax1.loglog(freqs, abs(ppsd_time))\n",
    "ax1.loglog(freqs, abs(ppsd_freq), alpha=0.5)\n",
    "\n",
    "ax2.loglog(freqs, abs(dis_ppsd_analytic))\n",
    "ax2.loglog(freqs, abs(dis_ppsd_time))\n",
    "ax2.loglog(freqs, abs(dis_ppsd_freq), alpha=0.5)\n",
    "\n",
    "ax3.loglog(freqs, abs(zp_ppsd_analytic))\n",
    "ax3.loglog(freqs, abs(zp_ppsd_time))\n",
    "ax3.loglog(freqs, abs(zp_ppsd_freq), alpha=0.5)\n",
    "\n",
    "ax1.set_ylabel('amplitude (m^2/s^2)')\n",
    "\n",
    "ax1.loglog(spec_ppsd.data.columns, abs(spec_ppsd.data.iloc[0]), alpha=0.8)\n",
    "ax2.loglog(spec_ppsd.data.columns, abs(spec_ppsd.data.iloc[1]), alpha=0.8)\n",
    "ax3.loglog(spec_ppsd.data.columns, abs(spec_ppsd.data.iloc[2]), alpha=0.8)\n",
    "\n",
    "ax1.loglog(spec_ppsd.data.columns, abs(spec_ppsd1[0]), alpha=0.8)\n",
    "ax2.loglog(spec_ppsd.data.columns, abs(spec_ppsd1[1]), alpha=0.8)\n",
    "ax3.loglog(spec_ppsd.data.columns, abs(spec_ppsd1[2]), alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_fd = np.sum(abs(spec_ppsd.data), axis=1) \n",
    "power_fd1 = np.sum(abs(spec_ppsd1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=[\"Integrated Velocity\", \"Analytical Velocity by PPSD\", \"Time Domain Velocity by PPSD\", \"Frequency Domain Velocity by PPSD\", \"Ratio\"])\n",
    "# Continuous pulse\n",
    "integrated = np.trapz(source_vel**2, dx=dt)\n",
    "analytic = np.sum(abs(ppsd_analytic))\n",
    "td = np.sum(abs(ppsd_time))\n",
    "fd = np.sum(abs(ppsd_freq))\n",
    "ratio = td/fd\n",
    "df.loc[\"Continuous\"] = [integrated, analytic, td, fd, ratio]\n",
    "# Discontinuity\n",
    "integrated = np.trapz(dis_source_vel**2, dx=dt)\n",
    "analytic = np.sum(abs(dis_ppsd_analytic))\n",
    "td = np.sum(abs(dis_ppsd_time))\n",
    "fd = np.sum(abs(dis_ppsd_freq))\n",
    "ratio = td/fd\n",
    "df.loc[\"Discontinuity\"] = [integrated, analytic, td, fd, ratio]\n",
    "# Zero padded (half-width pulse)\n",
    "integrated = np.trapz(zp_source_vel**2, dx=dt)\n",
    "analytic = np.sum(abs(zp_ppsd_analytic))\n",
    "td = np.sum(abs(zp_ppsd_time))\n",
    "fd = np.sum(abs(zp_ppsd_freq))\n",
    "ratio = td/fd\n",
    "df.loc[\"Zero Padded\"] = [integrated, analytic, td, fd, ratio]\n",
    "df.loc[\"Continuous\", \"MoPy\"] = power_fd[0]\n",
    "df.loc[\"Discontinuity\", \"MoPy\"] = power_fd[1]\n",
    "df.loc[\"Zero Padded\", \"MoPy\"] = power_fd[2]\n",
    "df.loc[\"Continuous\", \"MoPy_hybrid\"] = power_fd1[0]\n",
    "df.loc[\"Discontinuity\", \"MoPy_hybrid\"] = power_fd1[1]\n",
    "df.loc[\"Zero Padded\", \"MoPy_hybrid\"] = power_fd1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the mopy hybrid results are off as a result of how columns get selected on dataframes when their values are numeric. I'm leaving that in here to illustrate a point, because it took me so long to figure out what it was doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
