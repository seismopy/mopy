{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoPy Design Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This design document outlines the MoPy high level framework. It highlights what how we anticipate the user to interact with MoPy and provides a talking point and reference. \n",
    "\n",
    "A link to minutes from each day of the meeting, outlines discussion and outcomes:\n",
    "\n",
    "https://docs.google.com/document/d/1c_OaG1QaZWoOYvkM2p1fNcpk3k4g8kMr2e_vrEfFrTA/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.clients.fdsn import Client \n",
    "import mopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoPy will require some inputs at minimum in order to calculate Magnitudes.\n",
    "\n",
    "## Waveforms\n",
    "\n",
    "You can initialize an event client (ObsPy) or point to a waveform directory. This will make use of ObsPlus's wavebank feature.\n",
    "\n",
    "## Event catalog (ObsPy)  \n",
    "\n",
    "It contains at minium the event origin information i.e. lat (deg), lon (deg), depth (m) (relative to sea level - or at least the same datum of the velocity model), orgin time (UTC). \n",
    "\n",
    "***obspy.read_events will read many arbitrary catalog formats***   \n",
    "\n",
    "## Station Metadata (ObsPy - Inventory) \n",
    "\n",
    "Inventory includes the station lat, lons, elev and instrument response info (time dependent).\n",
    "\n",
    "## Windows (custom MoPy class)\n",
    "\n",
    "This class contains the time windows that will be used to convert to the frequency domain. We decided to allow the user to define custom windows and just pass those through manually should they wish. The class will also have some basic ability to create basic time windows as shown in the code. The user will label the phase and many arbitrary phases may be passed through for simulataneous computation. \n",
    "\n",
    "## Source Velocity (scalar) - not needed\n",
    "\n",
    "At least a constant value must be passed for velocity at the source. Multiple source velocities may be passed, but must be passed in the same order as the windows. \n",
    "\n",
    "***If this is not passed MoPy will look at .mopy.py for custom functions to define source velocity (to allow arbitrary 1/2/3/4D models)***\n",
    "\n",
    "## Source Model\n",
    "\n",
    "In order to obtain parameters for source modeling, we need to specifiy source models to fit the spectra too. We will have some built-in models commonly used for spectral modeling i.e. Brune, Boatright. However we also allow the user to specify an arbitrary source model. We use scipy's optimisation toolkit, so the only requirement is that the function should be created with this in mind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a client to use to download waveforms\n",
    "client = Client('IRIS')\n",
    "# Read a local catalog e.g. QuakeML\n",
    "cat = obspy.read_events('path_to_catalog')\n",
    "# Read a local station inventory file\n",
    "inv = obspy.read_inventory('path_to_inventory')\n",
    "# channel info stores everything in a relational database \n",
    "chan_info = mopy.ChannelInfo(waveforms=client, catalog=cat, inventory=inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define phase picks and time windows for spectral analysis and others:\n",
    "    1. Velocities \n",
    "    2. Source Density\n",
    "    3. Geometric Spreading\n",
    "    4. Free Surface Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 - define a dictionary\n",
    "picks = {(\"P\", \"event1\", \"UU.TMU..ELZ\"): UTCDateTime(2019, 1, 1, 0, 0, 0),\n",
    "         (\"S\", \"event1\", \"UU.TMU..ELZ\"): UTCDateTime(2019, 1, 1, 0, 0, 0.5)}\n",
    "chan_info.set_picks(picks)\n",
    "\n",
    "# Option 2 - use a csv file\n",
    "picks = pd.read_csv(\"my_picks.csv\")\n",
    "chan_info = chan_info.set_picks(picks)\n",
    "\n",
    "# can set just time windows or define relative to picks in the same manner as above\n",
    "chan_info.set_rel_time_windows(P=(0,1), S=(1,10), inplace=True)\n",
    "\n",
    "\n",
    "twinds = {(\"P\", \"event1\", \"UU.TMU..ELZ\"): (UTCDateTime(2019, 1, 1, 0, 0, 0), UTCDateTime(2019, 1, 1, 0, 0, 1))\n",
    "         (\"S\", \"event1\", \"UU.TMU..ELZ\"): (UTCDateTime(2019, 1, 1, 0, 0, 1), UTCDateTime(2019, 1, 1, 0, 0, 10))}\n",
    "chan_info = chan_info.set_abs_time_windows(twinds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass waveforms, catalog, inventory, time/phase windows, source velocity, source model(s) to `mopy.fit_spectra`. Calls the low level abstractions and passes all arguments. Fits all spectra from all phases and using all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an arbitrary source model function\n",
    "def  ArbSourceModel():\n",
    "        return omega_O, f_c\n",
    "    \n",
    "specs = mopy.fit_spectra(chan_info, source_model=('brune', 'boatright', ArbSourceModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a dataframe with all of the source parameters added to the dataframe returned in specs using all of the fitted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = mopy.calc_mw(specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save database to arbitrary format or add to a catalog object. Does some test to see if there is an existing database to append to. We can take advantage of the many database formats that pandas supports. We can also append to existing databases with each run. We may also add some of our features to the catalog object, which can be used in later ObsPy-based workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to QuakeML\n",
    "newcat = mags.add_to_cat(cat, inplace=False, **kwargs) \n",
    "# append to local database\n",
    "mags.to_database(path='path_to_storage', fmt='sql', if_exists='append', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defaults are stored in .defaults.py \n",
    "We want to streamline the user interface to MoPy as much as we can. We therefore will have a default signal processing workflow so a user can easily pick up and play. Power users may then experiment with different workflows and source models. Other more complicated abstractions may be changed in here.\n",
    "\n",
    "Defaults include:\n",
    "1. Signal processing workflow - Rotate? Pad Zeros? Taper? FFT? Multi-taper?\n",
    "2. Complex velocity models (1/3/4D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
